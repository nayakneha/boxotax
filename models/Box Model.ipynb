{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from IPython.core.debugger import set_trace\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for pairs\n",
    "class BoxDataset(Dataset):\n",
    "  \"\"\"Dataset wrapping images and target labels for Kaggle - Planet Amazon from Space competition.\n",
    "\n",
    "  Arguments:\n",
    "      A CSV file path\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, csv_path):\n",
    "    data = np.loadtxt(csv_path)\n",
    "    self.len = len(data)\n",
    "    self.X_train = torch.from_numpy(data[:,:2].astype(np.long))\n",
    "    self.y_train = torch.from_numpy(data[:,2].astype(np.float32))\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.X_train[index], self.y_train[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.len\n",
    "\n",
    "# Model = a tensor of boxes\n",
    "class Boxes(nn.Module):\n",
    "  def __init__(self, num_boxes, dim):\n",
    "    super(Boxes, self).__init__()\n",
    "    box_mins = torch.rand(num_boxes, dim)\n",
    "    box_maxs = box_mins + torch.rand(num_boxes, dim) * (1 - box_mins)\n",
    "    boxes = torch.stack([box_mins, box_maxs], dim=1)\n",
    "    self.boxes = nn.Parameter(boxes)\n",
    "    \n",
    "  def forward(self, X):\n",
    "    \"\"\"Returns box embeddings for ids\"\"\"\n",
    "    #set_trace()\n",
    "    x = self.boxes[X]\n",
    "    o = cond_probs(x[:,0,:,:], x[:,1,:,:])\n",
    "    return o\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_IND, MAX_IND = 0, 1\n",
    "\n",
    "def volumes(boxes):\n",
    "  r = (boxes[:,MAX_IND,:] - boxes[:, MIN_IND,:]).clamp(0).prod(1)\n",
    "  return r\n",
    "\n",
    "def intersections(boxes1, boxes2):\n",
    "  #set_trace()\n",
    "  intersections_min = torch.max(boxes1[:, :, MIN_IND], boxes2[:, :, MIN_IND])\n",
    "  intersections_max = torch.min(boxes1[:, :, MAX_IND], boxes2[:, :, MAX_IND])\n",
    "  apap = torch.stack([intersections_min, intersections_max], 1)\n",
    "  return apap\n",
    "\n",
    "def cond_probs(boxes1, boxes2):\n",
    "  return volumes(intersections(boxes1, boxes2))/volumes(boxes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = BoxDataset(\"data/sample/train.txt\")\n",
    "train_dl = DataLoader(train_ds, batch_size=18, shuffle=True, num_workers=4)\n",
    "\n",
    "model = Boxes(6,4)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 100\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    # Train\n",
    "    model.train()  # IMPORTANT\n",
    "    \n",
    "    running_loss, correct = 0.0, 0\n",
    "    for X, y in train_dl:\n",
    "      #set_trace()\n",
    "      #X, y = X.to(device), y.to(device)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      with torch.set_grad_enabled(True):\n",
    "        y_ = model(X)\n",
    "        loss = criterion(y_, y)\n",
    "\n",
    "      loss.backward()\n",
    "      \n",
    "      for param in model.parameters():\n",
    "          print(param.grad.data.sum())\n",
    "      print(model.boxes[0])\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Statistics\n",
    "      print(\"    batch loss: \"+str(loss.item()))\n",
    "      #_, y_label_ = torch.max(y_, 1)\n",
    "      #correct += (y_label_ == y).sum().item()\n",
    "      running_loss += loss.item() * X.shape[0]\n",
    "\n",
    "    print(\"  Train Loss: \"+str(running_loss / len(train_dl.dataset)))\n",
    "    print(\"  Train Acc:  \"+str(correct / len(train_dl.dataset)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
